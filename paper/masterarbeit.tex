\documentclass[a4paper,10pt]{article}
\usepackage[english]{lsspub} % default is babel's ngerman
\usepackage{pgf}
\usepackage{physics}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage[parfill]{parskip}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{import}
\usepackage{todonotes}

% SETUP OF LSSPUB
\lsstitle{Optimization of Mirrorshapes in Optically Pumped Solar Lasers Using Ray Tracing Simulation Techniques}%
\lssauthor{Matthias König}%
\lsstype{Master's Thesis}%
\lssabstract{
\normalsize
This work showcases the application of ray tracing techniques for the calculation of absorption profiles in
optically pumped solar lasers.
It aims at using a lightweight and fast physically based raytracer combined with a biobjective
mesh adaptive direct search algorithm to optimize total power absorption and to minimize variance across the crystal.
An exemplatory setup of a side pumped Nd:Yag solar laser was simulated, optimized and the resulting
beam quality evaluated.
}

% CONDITIONALLY SET UP PDF-SPECIFIC STUFF (OPTIONAL)
\usepackage{ifpdf}

\ifpdf
% look at documentation for non-pdflatex setup of hyperref
\usepackage[pdftex]{hyperref}
\usepackage{natbib}
\hypersetup{colorlinks=true}
\hypersetup{linkcolor=black}
\hypersetup{citecolor=black}
\hypersetup{pdfauthor=\lsstheauthor}
\hypersetup{pdftitle=\lssthetitle}
\hypersetup{pdfsubject={\lssthetype, Informatik 10, Universität Erlangen-Nürnberg}}
\hypersetup{pdfkeywords={Solar Laser, Raytracing, MADS, Blackbox Optimization}}

% if you want thumbnails for your pdf, you need an additional
% call of thumbpdf and pdflatex after pdflatex converged 
% (i.e. all references were resolved etc.)
%
%\usepackage{thumbpdf}
%\hypersetup{pdfpagemode=UseThumbs}
\fi

% START LATEX DOCUMENT BODY

\renewcommand{\vec}[1]{\mathbf{#1}}
\newcommand{\equref}[1]{Eq.~(\ref{#1})}
\newcommand{\secref}[1]{Section~\ref{#1}}
\newcommand{\figref}[1]{Figure~\ref{#1}}
\newcommand{\algref}[1]{Algorithm~\ref{#1}}
\newcommand{\tabref}[1]{Table~\ref{#1}}

\begin{document}

    % The following command creates the title page(s) and the text required
    % by the Pruefungsamt, stays German even if english option enabled
    % You can optionally provide a date for the signature line),
    % otherwise \today is used.
    \makelssthesis{Prof.~Dr.~C.~Pflaum}{1.11.2021 -- 2.5.2022}

    % Now the acutal thesis can start

    \tableofcontents

    \newpage

    \section{Introduction}

    In the light of the recent developements in global energy policy,
    renewable energy has become one of the most important
    problems humanity has to solve.
    Ever new ways of exploiting the sun's vast amount of energy are
    becoming relevant if nations across the world want to achieve
    net zero carbon emissions.
    One of those novel methods is the generation of hydrogen from
    water using solar energy.
    It can be achieved by common electrolysis or by reacting alkali
    metals with water.
    Researchers have been specifically looking at reacting magnesium
    ($Mg$) with water ($H_2O$) to produce hydrogen ($H_2$) and magnesium oxide
    ($MgO$)~\cite{solar_lasers_paper}.
    This reaction is exotherm and therefore causes a large amount of heat
    and produces hydrogen gas which could be stored in hydrogen fuel cells.
    Now if one can reduce the magnesium oxide to pure magnesium using
    the suns energy one would have a solution to store solar energy
    using hydrogen.
    To drive the reduction of magneisum oxide a laser can be used but
    a considerable amount if energy is needed.
    In order to reduce losses that are induced by using a conventional
    solar panel that drives a diode to pump the laser, it could be
    benefitial to pump the laser crystal directly using sunlight.
    This is exactly what Shigeaki Uchida and his team in Japan have
    been researching~\cite{solar_lasers_wiki}~\cite{solar_lasers_magnesium}.
    
    Another area of application that is becoming increasingly relevant is
    the usage of solar lasers in space exploration.
    Since there is no access to grid power in space and nuclear power
    is coupled with significant costs solar power is the most used
    source of power in space.
    The low efficiency of solar panels and the reduced number of parts
    of solar lasers make them an interesting prospect for usage in
    space.
    As mass is a high cost factor in space exploration the reduced weight
    and lower number of potential points of failure solar lasers could
    become a more relevant option in the future.
    The tasks of a solar laser in space could range from deep space
    communication, remote power transmission or tracking of objects.

    Solar lasers require the collection of sunlight and focusing
    onto a gain medium to surpass the lasing threshold thereof.
    As it is the most simple and cost effective method, usually
    a primary collector is used together with a secondary mirror in a 
    two stage collector to focus the sunlight onto the gain medium
    ~\cite{solar_lasers_magnesium}.
    The primary collector can be another mirror or a fresnel lens
    as a cheaper alternative.
    The beam power and quality is significantly impacted by the
    amount of power absorbed by the gain medium and the uniformity
    of the absorption profile.
    The natural divergence of sunlight and dispersion effects in the
    fresnel lens make it important that the secondary mirror is shaped
    in an optimal way.
    Both absorbed power and the uniformity of absorption need to be
    optimized.
    For the optical design of the collection system it is benefitial
    that the system is simulated accurately beforehand.
    For both the simulation and optimization part of the design process
    a free and open source framework was developed in this work in the
    hope that parts or the entirety of code may prove useful to engineers
    designing solar lasers.
    The goals of the framework are to offer a simple yet powerful interface
    for C++ applications.
    It provides a fast 2D paraxial raytracer for the calculation of the
    absorption profile in the gain medium which is then used by a
    mesh adaptive direct search algorithm in a biobjective manner (BIMADS) 
    to increase both absorbed power and uniformity of the absorption profile.
    This is done via the open source library NOMAD version 3~\cite{nomad3},
    which implements the MADS~\cite{mads_original} algorithm and a biobjective
    variant of it. 
    It offers the efficient derivative free optimization of a black-box
    function with constraints.

    The application of the framework is then demonstrated via an examplatory
    setup of a Nd:YAG solar laser using a two stage concentrator consisting
    of a fresnel lense and a secondary mirror.
    In principle, any parameter of the setup can be optimized but for this
    example in particular the mirrorshape is the interesting property. 
    The result of the BIMADS algorithm is a pareto front of optimal points 
    determined by the algortihm.
    Depending on whether a more even distribution of power is desired or
    the total amount of power absorbed is relevant to the application,
    some points of the pareto front are then chosen and simulated with
    the software ASLD~\cite{asld_website} to evaluate the resulting beam properties.

    \newpage

    \section{Lasers}

    Laser is an acronym which stands for \b{L}ight \b{A}mplification
    by \b{S}timulated \b{E}mission of \b{R}adiation.
    Lasers amplify coherent radiation at the infrared, visible, or
    ultraviolet part of the electromagnetic spectrum~\cite{lasers_siegman}.
    The principle was originally used in so called masers the 
    amplification of \b{M}icrowave radiation or even radio frequencies.
    The advantages of using a laser system as a lightsource are that
    they produce a directional beam of coherent light which can be 
    focused to a narrow spot~\cite{lasers_liverpool}.
    Additionally the emitted light is usually of a very narrow spectrum
    and thus reduces dispersion effects when shooting the beam through
    different media.
    Lasers are therefore used in a wide variety of applications which
    range from manufacturing processes to measuring systems to 
    optical communication.

    A laser usually consists of a gain medium that is capable of amplifying
    light that passes through by stimulated emission, a pumplight to
    excite the atoms of the gain medium to higher quantum states and
    an optical feedback mechanism - often called cavity or oscillator - 
    which usually
    consists of two mirrors that bounce the light back and forth through
    the gain medium~\cite{lasers_siegman}.
    One of those mirrors is only partially reflective and is transparent
    so that a portion of the amplified light can escape.
    Usually in more complex setups cooling is applied to the gain medium
    and some other optical elements like
    lenses or polarization filters may be present to ensure a better
    output beam quality.
    An ideal output beam is both temporally and spatially coherent,
    meaning that the emitted light is a perfect sine wave with constant
    amplitude und frequency and has a definite amplitude and phase pattern
    across any transverse plane inside the laser~\cite{lasers_siegman}.

    \subsection{Stimulated Emission}

    There are three ways in which atoms exchange energy with a radiation
    field~\cite{lasers_liverpool} identified by Albert Einstein.
    There is absorption where an electron is excited by a photon to a higher
    quantum energy state.
    Hereby the photon must have the exact amount of energy (wavelength)
    that the difference between energy state is.
    Then there is spontaneous emission where the excited electron jumps
    back to a lower energy state, emitting a photon in a random direction
    with a random phase shift
    but again with the same amount of energy as the difference between 
    states of the electron.
    This can occur spontaneously at any time as the name suggests. 
    The main priciple why the gain medium amplifies light is the priciple
    of stimulated emission.
    Electrons in the gain medium are stimlated by photons to a higher
    energy state.
    If now a again photon with the same amount of energy and a certain
    direction hits the atom the electron jumps back to the lower state
    again emitting a photon of the same energy but crucially and contrary
    to spontaneous emission in the exact same direction and the exact
    amount of phase shift as the incoming photon.
    Therefore amplifying the light by essentially "duplicating" the incoming
    photon.

    Now if one wants a coherent output beam one needs to make sure that
    the photons are travelling only in one direction and with constant
    phase.
    This is the job of the resonator.
    It uses the photons from spontaneous emission which at some point
    will have the correct direction and bounce them between the mirrors.
    Photons with other directions will be lost from the sides entirely
    or will get absorbed again by the medium.
    Due to this process a majority of photons will be travelling in the
    desired direction after some time.

    \subsection{Gain Medium and Population Inversion}

    In order to be able to amplify the emitted light, more atoms in the
    gain medium have to be in an already excited higher state than
    in the lower state.
    Otherwise "duplicated" photons will be reabsorbed by atoms in lower
    state and will not be able to stimulate another emmission or make
    it out of the laser cavity.
    Hence the population of atoms needs to be inverted~\cite{lasers_liverpool}.
    For this to happen an external source of energy needs to be supplied.
    This is called pumping and is usually achieved by a pump flash light
    or another laser.
    As it is equally likely that a photon causes stimulated emission or
    absorption there can not be only two states but at least three
    states are needed in optically pumped lasers~\cite{lasers_rpphotonics}.
    The electrons are then excited into the highest state by the pump
    light from which they can decay into the middle state ready for
    stimulated emission.
    It is crucial for level three lasers that the pump light cannot
    push the electrons in the middle state back to ground state.
    This way it is possible to have more atoms in the middle state than
    in ground state and therefore population inversion is achieved.
    For this to happen the pump light intensity in level three lasers
    needs to be sufficiently high enough for the photons to be "ignored"
    by the electrons in the second state.
    The threshold for the pump power to achieve population inversion
    is called the \emph{lasing threshold} and due to the
    energy levels in the atoms the choice of gain medium usually
    implies the choice of pump light or vice versa.  

    Materials that offer this property can be in gas, liquid or solid form.
    Solid form lasers are usually some sort of ion doped crystals or
    semiconductor diodes~\cite{lasers_liverpool}.
    As an example for a three level gain medium ruby ($Cr^{3+}:Al_2O_3$)
    can be used.
    In practice mostly four level gain media are used as they offer a 
    far lower lasing threshold for the pump power~\cite{lasers_rpphotonics}.
    These are usually neodymium doped media like the most popular choice
    neodymium doped yttrium aluminum garnets (Nd:YAG).

    \section{Raytracing Framework}
    With the advent of cheap processors and increasingly powerful 
    consumer hardware, ray tracing has become more popular in
    recent years.
    For the purpose of global illumination in video games and image
    processing, more advanced techniques have been continuously
    developed and improved.
    In optical design ray tracing is used to analyse the imaging 
    quality of optical systems or as in this work other 
    illumination properties can be simulated.
    The need for fast refresh rates in video games and the requirement
    of modelling more complex physical phenomena in optical design
    have led to tracing and sampling techniques that reduce the
    computational expense dramatically with minimal loss of accuracy. 
    Focused on the specific problems of laser design, these
    improvements make it possible to get physically accurate results
    in an acceptable amount of computational time in an iterative
    context.

    As in optical design systems are mostly rotationally symmetrical,
    the framework is meant to be used in a two dimensional setup
    and calculated quantities, e.g. absorbed power in a medium 
    converted to three dimensional values after a simulation step.
    This significantly reduces the amount of rays needed to avoid
    undersampling effects and to produce stable results across multiple
    simulation runs.
    Intersection tests also require less computation and objects in the
    scene require less fundamental shapes to test a ray against.
    The resulting performance gains makes it possible to run the 
    simulation thousands of times in an iterative process to 
    optimize some parameters in the optical setup even on consumer
    grade hardware.
    The objects in a scene are preproccessed to group fundamental shapes
    into leaves of a quadtree to reduce the amount of shapes a ray has
    to be tested against even further.
    To achieve the satisfied accuracy and to reduce noise the appropiate
    sampling strategies have to be used for a given problem.
    The most important techniques are provided including 
    uniform sampling, stratified and importance sampling.
    
    The framework was designed to provide a simple yet powerful
    interface for the user and was implemented in C++17.
    It provides the necessary data structures and algorithms for
    a fast raytracing solution.
    The sampling techniques are implemented in specialized classes
    of abstract interfaces. 
    They can also be used by the user to 
    implement custom techniques.
    The framework extensively relies on lambda functions to be
    provided by the user and thus naturally is customizable,
    although some preset functions are also provided.
    Because the calculations in the framework are so similar to applications
    in graphics software the OpenGL Mathematics header only library
    GLM~\cite{glm} was used as an underlying maths library.
    GLM is based on the OpenGL Shading Language (GLSL) and so in a 
    potential later step the framework
    could be ported to work on graphics cards providing that the
    data structures are changed to be accessable from a GPU.
    As in the specific problem in this work the tracing of each ray
    has side effects on the scene and on itself,
    i.e. the absorbed power of each ray has to be accumulated,
    it was decided to focus more on single core performance first
    and leave the parallel execution and execution on GPUs for a 
    later point.
    Furthermore IO utilities for simulations are provided for Comma 
    Separated Values (CSV) files and structured output for the 
    commonly used Visualization Toolkit (VTK)~\cite{vtk}.

    In the following chapters the applied ray tracing techniques 
    explained in detail.
    Firstly the basics of raytracing, i.e. intersection tests of
    fundamental shapes and objects and reflection and refraction effects
    are shown.
    Then an applied method of subdivision for the performance optimization
    of the raytracer is explained.
    Lastly some methods of sampling are shown before the structure of the 
    developed framework is presented with code samples.
    Here the usage of classes is demonstrated and it is shown how specific
    objects are defined.
    In particular the objects which are relevant for the simulation
    of laser cavities and which are used in the example setup are shown.

    \subsection{Raytracing Basics}  

    Rays are represented as a parametric line from a ray origin $o$ in
    direction $d$.
    The parameter $t$ goes is in the interval $[0, \infty)$ and represents
    the closeness of the ray to the origin.
    The mathematical representation therefore is given as

    \begin{equation}
        \label{equ:ray}
        \vec{r}(t) = \vec{o} + t\vec{d}
    \end{equation}

    After the ray is generated it is tested against intersections with the
    scene.
    Here the smallest $t > 0$ of all the intersections with objects has to
    be found.
    The question if a ray intersects an object can usually only be answered
    for simple fundamental shapes, e.g. lines, circles, axis aligned bounding
    boxes (AABBs) in 2D or planes, triangles, spheres, etc. in 3D.
    Therefore objects are normally comprised of a collection of fundamental
    shapes and an intersection occurs if one of the fundamental shapes is
    intersected.
    Naturally, an object can be intersected multiple times by the same ray
    and so the results have to be searched for the smallest $t$.
    Each fundamental shape should be represented in a parametrised form 
    so the intersection test can be represented as a system of equations.
    The two fundamental shapes used in this work are 2D lines and axis
    aligned bounding boxes (AABBs).

    Lines are represented by two points $\vec{a}$ and $\vec{b}$.
    So the intersection problem can be written as a ray-ray intersection
    as follows:

    Find $\alpha \in [0,1]$ and $t \in [0, \infty)]$ s.t. 

    \begin{equation}
        \label{equ:line_intersect}
        \vec{a} + \alpha (\vec{b} - \vec{a}) = \vec{o} + t \vec{d}
    \end{equation}

    If such a combination of $\alpha$ and $t$ exists, we have an intersection.
    As we are in 2D there are two equations for two unknowns and the
    system always has a solution.
    The solution can then be checked, s.t. the values are in the right
    intervals.
    A small mathematical trick is to define a 2D cross product which
    is basically just the $z$ component of a 3D cross product if the
    two input vectors $\vec{p}$ and $\vec{q}$ were parallel to the
    $xy$ plane:
    
    \begin{equation}
        \label{equ:2d_cross}
        \vec{p} \cross \vec{q} = 
        p_x \cdot q_y - p_y \cdot q_x \in \mathbb{R}
    \end{equation}

    Observe that same as the 3D cross product, the 2D version becomes 0
    when you cross a vector with itself.
    If one now crosses \equref{equ:line_intersect} with $\vec{d}$ on
    both sides the intersection equation becomes:
    
    \begin{equation}
        \label{equ:line_intersect_elim}
        \vec{a} \cross \vec{d} + \alpha (\vec{b} - \vec{a}) \cross \vec{d} =
        \vec{o} \cross \vec{d}
    \end{equation}

    So $t$ has been eliminated from the equation and we can solve 
    \equref{equ:line_intersect_elim} for $\alpha$:

    \begin{equation}
        \label{equ:line_intersect_alpha}
        \alpha = \frac{(\vec{a} - \vec{o}) \cross \vec{d}}
                      {\vec{d} \cross (\vec{b} - \vec{a})}
    \end{equation}

    If $\alpha$ satisfies the condition, we continue analogously for
    $t$ by crossing \equref{equ:line_intersect} with $\vec{b} - \vec{a}$.
    The resulting $t$ is then checked against the condition and
    a normal at the intersection point is calculated.
    The intersected rays can be seen in in \figref{fig:line_intersect}.

    \begin{center}
        \begin{figure}[H]
            \centering    
            \def\svgwidth{0.8\textwidth}
            \import{images/}{line_intersect.pdf_tex}
            \caption{
                Ray-line intersection of two rays. The line is specified by
                the points $\vec{a}$ and $\vec{b}$ and the rays are 
                defined by
                the origins $\vec{o}_i$ and directions $\vec{d}_i$.
                Ray $(\vec{o}_1, \vec{d}_1)$ satisfies the conditions 
                $t \geq 0$ and $0 \leq \alpha \leq 1$
                and therefore causes an intersection, ray $(\vec{o}_2, \vec{d}_2)$
                dissatisfies the $\alpha$ condition and ray $(\vec{o}_3, \vec{d}_3)$
                does not satisfy the $t$ condition. 
            }
            \label{fig:line_intersect}
        \end{figure}
    \end{center}

    Another important shape to intersect are AABBs.
    They are rectangles aligned with the axis of the coordinate system
    so they require minimal memory space and intersection tests are
    as simple as possible.
    They most often used to surround complex objects or parts of it
    to reduce the amount of intersection tests.
    First the AABB of the object is tested and only if there is an
    intersection the actual fundamental shapes inside the AABB are tested.
    A 2D AABB is defined by two points $\vec{b}_{min}$ and $\vec{b}_{max}$ which
    represent the lower left and upper right corner of the rectangle.
    The intersection test is done by comparing the values of $t$ at each
    of the axis aligned lines defining the box.
    The $t$ values for the $x$ axis aligned lines can be calculated as
    shown in \algref{alg:aabb_intersect}.

    \begin{algorithm}[H]
        \label{alg:aabb_intersect}
        \SetAlgoLined

        ${t_x}_1$ = $\frac{{b_{min}}_x - o_x}{d_x}$\;
        ${t_x}_2$ = $\frac{{b_{max}}_x - o_x}{d_x}$\;
        $t_{min}$ = $\min({t_x}_1, {t_x}_2)$\;
        $t_{max}$ = $\max({t_x}_1, {t_x}_2)$\;
        ${t_y}_1$ = $\frac{{b_{min}}_y - o_y}{d_y}$\;
        ${t_y}_2$ = $\frac{{b_{max}}_y - o_y}{d_y}$\;
        $t_{min}$ = $\max(t_{min}, \min({t_y}_1, {t_y}_2))$\;
        $t_{max}$ = $\min(t_{max}, \max({t_x}_1, {t_x}_2))$\;

        \If{$t_{min} \geq 0$ and $t_{min} \leq t_{max}$}{
            AABB was hit!
        }
        \caption{
        Intersection test for a AABB $(\vec{b}_{min}, \vec{b}_{max})$
        with ray $(\vec{o}, \vec{d})$
        }
    \end{algorithm}

    If the conditions $t_{min} \leq t_{max}$ and $t_{min} \geq 0$ hold
    there is an intersection.
    This process is better understood visually and is illustrated in 
    \figref{fig:aabb_intersect}.
    If normals are needed they can be easily calculated since there are
    only four possibilities depending on which side of the box is
    intersected first. 

    \begin{center}
        \begin{figure}[H]
            \centering    
            \def\svgwidth{0.6\textwidth}
            \import{images/}{aabb_intersect.pdf_tex}
            \caption{
                Ray-AABB intersection, where first the intersection points with
                the $x$ axis (marked in green) and $y$ axis (marked in blue) are
                calculated.
                Each of the values ${t_i}_1, {t_i}_2$ are then split into the minimum
                and the maximum of the two.
                Both maximums are then compared and the minimum is chosen as the final 
                $t_{max}$.
                Analogously the minimums are compared and the maximum is chosen as
                $t_{min}$ (marked with red circles).
                Thus there is an intersection with an entry point 
                $\vec{o} + t_{min}\vec{d}$ and an exit point 
                $\vec{o} + t_{max}\vec{d}$ and the normals can be calculated depending
                on which sides the points reside.
            }
            \label{fig:aabb_intersect}
        \end{figure}
    \end{center}

    The AABB intersection becomes really handy once one wants to use them
    for ray tracing acceleration techniques, as they can easily be constructed
    to surround a cloud of points and then be used as a spacial subdivider
    in a tree structure.
    This is described in detail in the next chapter.
    Other shapes like circles or ellipses are intersected in a similar way
    but as they are not used in the example below the intersection process
    is not explained here.

    Once an intersection takes place, the ray will be either reflected, terminated
    or refraction occurs depending on the desired material of the object.
    Total reflection is only dependent on the incident angle $\theta_i$ 
    to the normal of the surface at the hitpoint.
    Then the reflection angle $\theta_r$ is given by \equref{equ:reflection}.

    \begin{equation}
        \label{equ:reflection}
        \theta_r = -\theta_i
    \end{equation}

    A new ray is then generated at the hitpoint pointing in the direction
    given by $\theta_r$.
    Due to limited floating point precision, it is required that the origin
    of the new ray is shifted by a small $\epsilon$ towards the 
    reflection direction in order to make sure the ray is originated at the
    correct side of the material.
    Since the reflection is total the entire amount of power of the incident
    ray is transferred to the reflected ray.

    When hitting a material that is transmissible for light the ray
    will be refracted at the boundary between the two media.
    The effects of matter on a light beam are described by Snell's law
    and the Fresnel equations.
    The ray is split into a reflected and a transmitted ray.
    The direction of the transmitted ray is governed by Snell's law in \equref{equ:snell}
    which depends on the indices of refraction of the two media $n_i$ and $n_t$.

    \begin{equation}
        \label{equ:snell}
        n_i \sin(\theta_i) = n_t \sin(\theta_t)
    \end{equation}

    Naturally, the reflected ray is still reflected as given in
    \equref{equ:reflection}.
    The transmitted and reflected power can be calculated with the transmission- and
    reflection rates given by Fresnel's equations.
    These are dependent on the orientation of the polarization of the incident ray
    (perpendicular or parallel) to the surface.

    \begin{equation}
        \label{equ:fresnel}
		R_{\perp} = \frac{\sin^2(\theta_1 - \theta_2)}{\sin^2(\theta_1 + \theta_2)} \quad
		R_{\parallel} = \frac{\tan^2(\theta_1 - \theta_2)}{\tan^2(\theta_1 + \theta_2)} \quad
		T_{\perp} = 1 - R_{\perp} \quad
		T_{\parallel} = 1 - R_{\parallel}
    \end{equation}

    For unpolarized light the total rates are just given by the average.
    
    \begin{equation}
			R_{total} = \frac{R_{\perp} + R_{\parallel}}{2} \quad
			T_{total} = \frac{T_{\perp} + T_{\parallel}}{2}
    \end{equation}

    \subsection{Raytracing Acceleration}

    As the raytracer is later intended to be used in an iterative optimization
    algorithm, it is of vital importance that unnecessary computational cost 
    is avoided.
    For a raytracer this can be achieved in a number of ways.
    The first and simplest way is to simply reorder the objects in a scene
    by a heuristic that describes the likelihood of on object to be the
    first object hit by the majority of the rays.
    Of course, this only works well if rays are shot into a scene from
    a dominant direction.
    Another way would be to subdivide the entire 2D scene with quadtrees
    and try to fill each branch of the tree with an equal amount of 
    objects or shapes.
    
    Similarly one can also subdivide an object itself and sort the
    fundamental shapes comprising that object into a quadtree.
    This method was chosen in this work as there are a limited amount of
    objects in the scene with the objects possibly being quite complex.
    Once the fundamental shapes of an object are known, they can be
    sorted into a quadtree of AABBs of a chosen depth.
    The outermost AABB is the root of the tree with four children,
    each encompassing the shapes inside their quarter of space
    as tightly as possible.
    This is recursively done until the desired depth is hit.
    The intersection test of an object then can be done by hitting
    the root AABB of the tree and then stepping through its children
    via breadth first search.
    Each AABB child the ray hits, is persued further and the ones
    the ray doesn't intersect are ignored.
    If a leaf has been hit all the shapes inside are then tested for
    intersection.
    Finally the $t$ values of all the intersections are compared and
    the minimum and the maximum chosen as entry and exit points. 
    The advantage of this is that AABB intersection tests are done really
    fast and a large number of fundamental shape intersection tests
    are avoided.
    An illustration of subdivision of a mirror comprised of line segments
    is given in \figref{fig:quadtree} and a the intersecting algorithm
    for a single object is givin in \algref{alg:object_intersect}.

    \begin{center}
        \begin{figure}[H]
            \centering    
            \includegraphics[width=0.8\textwidth]{images/mirror.png}
            \caption{
                A parabolic mirror comprised of line segments
                subdivided by a quadtree of AABBs with depth 4.
                Note that the AABBs are encompassing their contained line
                segments as tightly as possible.
            }
            \label{fig:quadtree}
        \end{figure}
    \end{center}

    \begin{algorithm}[H]
        \label{alg:object_intersect}
        \SetAlgoLined
        IntersectionResult objectResult\;
        objectResult.tEnter = MaxFloatingPoint\;
        objectResult.tLeave = MinFloatingPoint\;

        Queue treeQueue\;
        treeQueue.push(object.root)\;

        \While{!treeQueue.empty()}{

            tree = treeQueue.front()\;
            IntersectionResult aabbResult = tree.aabb.intersect(ray)\;
            \If{aabbResult.hit}{
                \For{shapes in tree.shapes}{
                    IntersectionResult shapeResult = shape.intersect(ray)\;
                    \If{shapeResult.hit}{
                        set objectResult appropiately\;
                    }
                }
                treeQueue.push(tree.children)\;
            }
            treeQueue.pop()\;
        }

        \caption{Intersection test for a single object subdivided by a quadtree}
    \end{algorithm}


    \subsection{Sampling Techniques}

    The accuracy and performance of ray tracing simulations are heavily dependent upon
    using the correct sampling techniques.
    One could sample values on a uniform grid or equally spaced intervals.
    The problem with this is that there is no randomness or irregularity
    causing structured aliasing errors in most applications. 
    Random sampling however always relies on some sort of random number generation.
    These are usually pseudo random numbers generated according to some
    distribution with the generation engine initialized with a seed.
    Usually when one samples according to some scheme only values in 
    $[0,1]$ are allowed.
    The returned sample is then later scaled to the desired range depending
    on the usecase.
    It is also to be noted that calls to a sampler must be ensured to
    be as effiecient as possible as a large number of calls will be
    made during the simulation.

    The simplest sampling scheme is uniform sampling.
    It returns values uniformly and can be implemented right on top of
    the random number engine of the used system.
    The advantage of uniform sampling is that it produces close to random
    samples without the need for additional logic and therefore
    performance losses.
    The disadvantage is the irregular density of samples within the interval.
    There can be areas with a lot of samples and large gaps between.
    So in scenarios where there needs to be a more regular distribution
    of samples uniform sampling is not optimal.

    For this reason another sampling technique called stratified uniform
    sampling exists.
    Here the domain is split into $N$ equally spaced intervals and the
    uniform sampling occurs within each interval.
    This ensures that there is some amount of regularity while still
    keeping the randomness of uniform sampling.
    An application of stratified sampling would be the definition of
    a light source in the simulation.
    The direction or origin of the rays the light source emitts can be
    sampled according to stratified sampling to ensure a smooth
    illumination of the scene.
    The difference between uniform and stratified uniform sampling can
    be observed in \figref{fig:uniform_vs_stratified}.

    \begin{center}
        \begin{figure}[H]
            \centering    
            \includegraphics[width=0.25\textwidth]{images/stratified.png}
            \caption{
                Uniform sampling of a 1D interval (left) vs. stratified sampling (right).
                Observe the large gap between samples on the left whereas
                the samples on the right are spaced out more equally.
            }
            \label{fig:uniform_vs_stratified}
        \end{figure}
    \end{center}

    A more advanced technique is to sample values where they are contributing
    the most.
    Suppose one wants to approximate some function $f$ over a domain
    $[0,1]$.
    The criterium that has to be met in order to calculate some quantity
    $Q$ is given by any arbitrary integral in the domain.
    With uniform sampling of $x \in [x_1,x_2]$ by the sequence 
    $(x_i)$ and $i = 1...n$ the integral is approximated
    by \equref{equ:impsampling_uniform}.

    \begin{equation}
        \label{equ:impsampling_uniform}
        Q = \int_{x_1}^{x_2} f(x) dx \approx \frac{1}{n} \sum_{i = 1...n} f(x_i)
    \end{equation}

    Now it is also possible to sample according to some other distribution.
    One just has to know the probability density function (pdf) $p$ to know
    how likely it is that a sample $x_i$ is generated.
    Probability density functions are nonnegative across the domain
    and their integral over the domain is always 1.
    This corresponds to the probability that a sampled value is in the
    interval $[x_1, x_2]$ which is of course the case when all
    possible values are within that interval. 
    The more accurately the pdf $p$ matches $f$ the more $[x_1,x_2]$
    is sampled at the points where the function $f$ has a large contribution to
    the integral.
    This can significantly reduce the amount of samples needed to get an
    accurate approximation for the integral $Q$.
    The integral is then approximated by \equref{equ:impsampling}.

    \begin{equation}
        \label{equ:impsampling}
        Q = \int_{x_1}^{x_2} f(x) dx \approx \frac{1}{n} \sum_{i = 1...n} \frac{f(x_i)}{p(x_i)}
    \end{equation}

    Observe that now the values for $f$ are weighted by the likelihood $p$.
    If it is likely that a sample $x_i$ is generated - larger $p$ - then
    the contribution is worth less and vice versa.     
    Of course this requires some preprocessing in order to generate the
    distribution $P$ from a pdf $p$.
    Usually one wants to generate $p$ from $f$ but there are also 
    cases where one might choose another function to deduce the
    pdf and subsequently the distribution.

    One method of building such a distribution is to first integrate
    $f$ in the domain $[x_1, x_2]$ and normalize the function so the
    integral is guaranteed to be 1.
    Then to sample according to the resulting pdf one discretizes the
    pdf to a finite amount of equidistant intervals $p_i = [{x_1}_i, {x_2}_i]$.
    For an interval $p_j$ the values $p({x_2}_i)$ for all $i < j$ are
    then summed up progressively assigned to that interval.
    These resulting rectangles are then stacked so that each rectangle
    represents an interval in $x$ and the corresponding values of the
    sum of the pdf.
    Then a sample $\xi \in [0,1]$ is drawn from a uniform sampler and
    the corresponding interval in which the value $\xi$ lies in is
    searched in the list of intervals using binary search.
    Once the interval is found we interpolate linearly between the
    lower boundary ${x_1}_i$ and ${x_2}_i$ depending on $\xi$.
    Then the resulting $x \in [{x_1}_i, {x_2}_i]$ is returned along
    the value of the pdf $p(x)$ as a sample.
    This process approximates the distribution $P$ and is called the
    inversion method. It is better understood when visualized as in
    \figref{fig:impsampling}. 
    
    \begin{center}
        \begin{figure}[H]
            \centering    
            \begin{tabular}{c c}
            \includegraphics[width=0.3\textwidth]{images/impsampling_rectangles.png} &
            \includegraphics[width=0.7\textwidth]{images/inversion.png}
            \end{tabular}
            \caption{
                Visualization of inversion method to sample according the
                pdf on the left.
                The intevals $p_i$ are summed up and stacked.
                Then a $\xi \in [0,1]$ is uniformly sampled and the corresponding
                interval is searched.
                The returned value is interpolated linearly according to the value
                of $/xi$ within the rectangle.
            }
            \label{fig:impsampling}
        \end{figure}
    \end{center}

    \subsection{Framework Structure}
    \subsubsection{Rays}
    \subsubsection{Shapes}
    \subsubsection{Objects}
    \subsubsection{Scene}
    \subsubsection{Tracing Algorithm}
    \subsubsection{Sampler}
    \subsubsection{IO Utilities}

    \subsection{Setup Specific Objects}
    \subsubsection{Lens}
    \subsubsection{Mirror}
    \subsubsection{Crystal}

    \section{Optimization}
    \subsection{Functional Analysis}
    \subsection{Mesh Adaptive Direct Search (MADS)}
    \subsection{Biobjective MADS}
    \subsection{Nomad Library}
    \subsection{Integration into Framework}

    \section{Examplatory Setup}
    \subsection{Setup}
    \subsection{ASLD Software}
    \subsection{Beam Analysis}

    \newpage

    \bibliographystyle{plain}
    \bibliography{bibliographies/references}

\end{document}
